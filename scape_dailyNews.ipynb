{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "import pymongo\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ListofDict(u,h,d,t):\n",
    "    listofdict = []\n",
    "    for c,lx in enumerate(u,0):\n",
    "        info = {\n",
    "            \"timestamp\": t,\n",
    "            \"URL\":    lx,\n",
    "            \"headline\": h[c],\n",
    "            \"newsdate\":  d[c]\n",
    "        }\n",
    "        listofdict.append(info)\n",
    "    return listofdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTHMonth(monthString):\n",
    "    switcher = {\n",
    "        \"มกราคม\": 1,\n",
    "        \"กุมภาพันธ์\": 2,\n",
    "        \"มีนาคม\": 3,\n",
    "        \"เมษายน\":  4,\n",
    "        \"พฤษภาคม\": 5,\n",
    "        \"มิถุนายน\": 6,\n",
    "        \"กรกฎาคม\": 7,\n",
    "        \"สิงหาคม\": 8,\n",
    "        \"กันยายน\": 9,\n",
    "        \"ตุลาคม\": 10,\n",
    "        \"พฤศจิกายน\": 11,\n",
    "        \"ธันวาคม\": 12}\n",
    "    return switcher.get(monthString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect MongoDB\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[\"BADS7101\"]\n",
    "q_c_urlList = mydb[\"URL_LIST_CRIME\"]\n",
    "q_p_urlList = mydb[\"URL_LIST_POLITIC\"]\n",
    "q_e_urlList = mydb[\"URL_LIST_ENTER\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_crime = 'https://www.dailynews.co.th/crime?page='\n",
    "urls_political = 'https://www.dailynews.co.th/politics?page='\n",
    "urls_entertain = 'https://www.dailynews.co.th/entertainment?page='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_c_urlList.delete_many({})\n",
    "\n",
    "for e in range(1,maxLen):\n",
    "    today = datetime.now()\n",
    "    driver = webdriver.Chrome(executable_path='selenium/chromedriver.exe')\n",
    "    driver.get(urls_crime+str(e))\n",
    "    content=driver.page_source\n",
    "    soup=BeautifulSoup(content,'lxml')\n",
    "    urlList,dtList,hList = [],[],[]\n",
    "    \n",
    "    for div in soup.find_all(\"div\", class_=lambda value: value and value==\"left\"):\n",
    "        for a in div.find_all(\"a\", class_=lambda value: value and value==\"media\", href=True):\n",
    "            urlList.append(\"https://www.dailynews.co.th\"+str(a['href']).strip())\n",
    "            for s in a.find_all(\"span\", class_=lambda value: value and value==\"media-date\"):\n",
    "                dstr = s.text.strip().split()\n",
    "                dt = str(dstr[1])+\"/\"+str(convertTHMonth(dstr[2]))+\"/\"+str(int(dstr[3])-543)+\" \"+str(dstr[5]).replace('.',':')\n",
    "                dtList.append(datetime.strptime(dt, '%d/%m/%Y %H:%M'))\n",
    "            for h in a.find_all(\"h3\", class_=lambda value: value and value==\"media-heading\"):\n",
    "                hList.append(str(h.text.strip()))\n",
    "    process_data = create_ListofDict(urlList,hList,dtList,today)\n",
    "    q_c_urlList.insert_many(process_data)\n",
    "    time.sleep(2)\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q_p_urlList.delete_many({})\n",
    "\n",
    "for e in range(207,421):\n",
    "    today = datetime.now()\n",
    "    driver = webdriver.Chrome(executable_path='selenium/chromedriver.exe')\n",
    "    driver.get(urls_political+str(e))\n",
    "    content=driver.page_source\n",
    "    soup=BeautifulSoup(content,'lxml')\n",
    "    urlList,dtList,hList = [],[],[]\n",
    "    \n",
    "    for div in soup.find_all(\"div\", class_=lambda value: value and value==\"left\"):\n",
    "        for a in div.find_all(\"a\", class_=lambda value: value and value==\"media\", href=True):\n",
    "            urlList.append(\"https://www.dailynews.co.th\"+str(a['href']).strip())\n",
    "            for s in a.find_all(\"span\", class_=lambda value: value and value==\"media-date\"):\n",
    "                dstr = s.text.strip().split()\n",
    "                dt = str(dstr[1])+\"/\"+str(convertTHMonth(dstr[2]))+\"/\"+str(int(dstr[3])-543)+\" \"+str(dstr[5]).replace('.',':')\n",
    "                dtList.append(datetime.strptime(dt, '%d/%m/%Y %H:%M'))\n",
    "            for h in a.find_all(\"h3\", class_=lambda value: value and value==\"media-heading\"):\n",
    "                hList.append(str(h.text.strip()))\n",
    "    process_data = create_ListofDict(urlList,hList,dtList,today)\n",
    "    q_p_urlList.insert_many(process_data)\n",
    "    time.sleep(2)\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_e_urlList.delete_many({})\n",
    "\n",
    "for e in range(1,maxLen):\n",
    "    today = datetime.now()\n",
    "    driver = webdriver.Chrome(executable_path='selenium/chromedriver.exe')\n",
    "    driver.get(urls_entertain+str(e))\n",
    "    content=driver.page_source\n",
    "    soup=BeautifulSoup(content,'lxml')\n",
    "    urlList,dtList,hList = [],[],[]\n",
    "    \n",
    "    for div in soup.find_all(\"div\", class_=lambda value: value and value==\"left\"):\n",
    "        for a in div.find_all(\"a\", class_=lambda value: value and value==\"media\", href=True):\n",
    "            urlList.append(\"https://www.dailynews.co.th\"+str(a['href']).strip())\n",
    "            for s in a.find_all(\"span\", class_=lambda value: value and value==\"media-date\"):\n",
    "                dstr = s.text.strip().split()\n",
    "                dt = str(dstr[1])+\"/\"+str(convertTHMonth(dstr[2]))+\"/\"+str(int(dstr[3])-543)+\" \"+str(dstr[5]).replace('.',':')\n",
    "                dtList.append(datetime.strptime(dt, '%d/%m/%Y %H:%M'))\n",
    "            for h in a.find_all(\"h3\", class_=lambda value: value and value==\"media-heading\"):\n",
    "                hList.append(str(h.text.strip()))\n",
    "    process_data = create_ListofDict(urlList,hList,dtList,today)\n",
    "    q_e_urlList.insert_many(process_data)\n",
    "    time.sleep(2)\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
